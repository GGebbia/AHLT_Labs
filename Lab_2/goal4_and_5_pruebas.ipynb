{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = \"data_Train_megam.dat\"\n",
    "test_filename = \"data_Devel_megam.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = open(train_filename, \"r\").read().split(\"\\n\")\n",
    "test_samples = open(test_filename, \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(word_features):\n",
    "    X_samples = []\n",
    "    sample = []\n",
    "    \n",
    "    Y_labels = []\n",
    "    label = []\n",
    "    \n",
    "    for word_feature in word_features:\n",
    "        if word_feature != \"\":\n",
    "            word_feature = word_feature.split(\" \")\n",
    "            label.append(word_feature[0])\n",
    "            sample.append(word_feature[1:])\n",
    "        else:\n",
    "            X_samples.append(sample)\n",
    "            Y_labels.append(label)\n",
    "\n",
    "            sample = []\n",
    "            label = []\n",
    "    return X_samples, Y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 368 ms, sys: 72.5 ms, total: 441 ms\n",
      "Wall time: 402 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "X_train, Y_train = split_data(train_samples)\n",
    "X_test, Y_test = split_data(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 822 ms, sys: 14.7 ms, total: 837 ms\n",
      "Wall time: 847 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, Y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.12 s, sys: 6.9 ms, total: 8.13 s\n",
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train(train_filename + '_model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_features': 3504,\n",
       " 'error_norm': 116.401182,\n",
       " 'feature_norm': 65.003895,\n",
       " 'linesearch_step': 1.0,\n",
       " 'linesearch_trials': 1,\n",
       " 'loss': 9534.191645,\n",
       " 'num': 50,\n",
       " 'scores': {},\n",
       " 'time': 0.102}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logparser.last_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 {'loss': 9534.191645, 'error_norm': 116.401182, 'linesearch_trials': 1, 'active_features': 3504, 'num': 50, 'time': 0.102, 'scores': {}, 'linesearch_step': 1.0, 'feature_norm': 65.003895}\n"
     ]
    }
   ],
   "source": [
    "print len(trainer.logparser.iterations), trainer.logparser.iterations[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fc9c5c31a90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(train_filename + '_model.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.3 ms, sys: 4.92 ms, total: 62.2 ms\n",
      "Wall time: 64.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_pred = [tagger.tag(xseq) for xseq in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-brand       0.62      0.14      0.23        71\n",
      "     I-brand       0.00      0.00      0.00         2\n",
      "      B-drug       0.74      0.46      0.57       349\n",
      "      I-drug       0.64      0.67      0.65        24\n",
      "    B-drug_n       0.00      0.00      0.00        34\n",
      "    I-drug_n       0.00      0.00      0.00         6\n",
      "     B-group       0.73      0.32      0.45       171\n",
      "     I-group       0.62      0.25      0.36       134\n",
      "\n",
      "   micro avg       0.71      0.35      0.47       791\n",
      "   macro avg       0.42      0.23      0.28       791\n",
      "weighted avg       0.66      0.35      0.45       791\n",
      " samples avg       0.02      0.02      0.02       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bio_classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "O      -> O       6.306696\n",
      "B-group -> I-group 5.584653\n",
      "B-drug_n -> I-drug_n 5.041959\n",
      "I-group -> I-group 4.873304\n",
      "I-drug_n -> I-drug_n 4.130055\n",
      "B-drug -> I-drug  3.704736\n",
      "B-brand -> I-brand 3.327522\n",
      "O      -> B-drug  3.271012\n",
      "I-drug -> I-drug  3.037962\n",
      "B-drug -> O       2.737865\n",
      "B-group -> O       2.628012\n",
      "B-drug_n -> O       2.242394\n",
      "B-brand -> O       2.182316\n",
      "O      -> B-group 2.092251\n",
      "I-group -> O       1.982841\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-drug_n -> B-brand -0.717688\n",
      "I-drug -> B-brand -0.756350\n",
      "I-brand -> B-brand -0.808869\n",
      "I-group -> B-brand -0.895362\n",
      "B-group -> B-group -0.965026\n",
      "O      -> I-drug  -0.986978\n",
      "B-group -> B-brand -1.223175\n",
      "B-brand -> B-group -1.403115\n",
      "O      -> I-brand -1.443811\n",
      "B-drug -> I-group -1.447992\n",
      "B-drug -> B-drug  -1.764949\n",
      "B-drug -> B-group -1.980907\n",
      "O      -> I-group -2.401827\n",
      "B-brand -> B-brand -2.716318\n",
      "B-drug -> B-brand -2.795083\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "info = tagger.info()\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common(15))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(info.transitions).most_common()[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

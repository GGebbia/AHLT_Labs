{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named nltk",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-88a91bbeaefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElementTree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWhitespaceTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named nltk"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, span_generator):\n",
    "    return [(sentence[span[0]: span[1]], span[0], span[1]-1) for span in span_generator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(tokenized_list):\n",
    "    entities_list = []\n",
    "    last_type = None\n",
    "    for i, word, offset_from, offset_to in enumerate(tokenized_list):\n",
    "        \n",
    "        d = {}\n",
    "        \n",
    "        if (word[0].isupper() and offset_from != 0) or (word.isupper()):\n",
    "            d[\"name\"] = word\n",
    "            d[\"type\"] = \"drug\" # Posar pes per fer probabilitat 2/3 si es drug, 1/3 si es brand\n",
    "            d[\"offset\"] = \"{}-{}\".format(offset_from, offset_to)\n",
    "            last_type = \"drug\"\n",
    "        \n",
    "        \n",
    "        if last_type != None\n",
    "        #TODO: si la paraula seguent tambe te el mateix tipus, merge\n",
    "        elif word.lower() = \"acid\":\n",
    "            prev_word, prev_offset_from, _ = tokenized_list[i-1]\n",
    "            \n",
    "            # Remove drug or brand if it was added since the next word is acid\n",
    "            if last_type != None:\n",
    "                entitites_list.pop(-1)\n",
    "            \n",
    "            d[\"name\"] = prev_word + \" acid\"\n",
    "            d[\"type\"] = \"drug\"\n",
    "            d[\"offset\"] = \"{}-{}\".format(prev_offset_from, offset_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Spermine', 0, 7), ('promotes', 9, 16), ('the', 18, 20), ('translocation', 22, 34), ('of', 36, 37), ('phosphatidate', 39, 51), ('phosphohydrolase', 53, 68), ('from', 70, 73), ('the', 75, 77), ('cytosol', 79, 85), ('to', 87, 88), ('the', 90, 92), ('microsomal', 94, 103), ('fraction', 105, 112), ('of', 114, 115), ('rat', 117, 119), ('liver', 121, 125), ('and', 127, 129), ('it', 131, 132), ('enhances', 134, 141), ('the', 143, 145), ('effects', 147, 153), ('of', 155, 156), ('oleate', 158, 163), ('in', 165, 166), ('this', 168, 171), ('respect.', 173, 180)]\n",
      "\n",
      "\n",
      "\n",
      "[('Spermine', 0, 7), ('(0.5-2', 9, 14), ('mM)', 16, 18), ('promoted', 20, 27), ('the', 29, 31), ('translocation', 33, 45), ('of', 47, 48), ('phosphatidate', 50, 62), ('phosphohydrolase', 64, 79), ('from', 81, 84), ('the', 86, 88), ('soluble', 90, 96), ('to', 98, 99), ('the', 101, 103), ('microsomal', 105, 114), ('fraction', 116, 123), ('in', 125, 126), ('a', 128, 128), ('cell-free', 130, 138), ('system', 140, 145), ('derived', 147, 153), ('from', 155, 158), ('rat', 160, 162), ('liver.', 164, 169)]\n",
      "\n",
      "\n",
      "\n",
      "[('By', 0, 1), ('contrast,', 3, 11), ('spermidine', 13, 22), ('(1', 24, 25), ('mM)', 27, 29), ('and', 31, 33), ('putrescine', 35, 44), ('(1', 46, 47), ('mM)', 49, 51), ('had', 53, 55), ('no', 57, 58), ('significant', 60, 70), ('effect', 72, 77), ('on', 79, 80), ('the', 82, 84), ('translocation', 86, 98), ('when', 100, 103), ('added', 105, 109), ('alone.', 111, 116)]\n",
      "\n",
      "\n",
      "\n",
      "[('Spermine,', 0, 8), ('and', 10, 12), ('to', 14, 15), ('a', 17, 17), ('lesser', 19, 24), ('extent,', 26, 32), ('spermidine,', 34, 44), ('enhanced', 46, 53), ('the', 55, 57), ('translocating', 59, 71), ('action', 73, 78), ('of', 80, 81), ('oleate', 83, 88), ('and', 90, 92), ('increased', 94, 102), ('its', 104, 106), ('effectiveness', 108, 120), ('in', 122, 123), ('transferring', 125, 136), ('the', 138, 140), ('phosphohydrolase', 142, 157), ('from', 159, 162), ('the', 164, 166), ('soluble', 168, 174), ('to', 176, 177), ('the', 179, 181), ('microsomal', 183, 192), ('fraction.', 194, 202)]\n",
      "\n",
      "\n",
      "\n",
      "[('It', 0, 1), ('is', 3, 4), ('proposed', 6, 13), ('that', 15, 18), ('the', 20, 22), ('phosphohydrolase', 24, 39), ('becomes', 41, 47), ('metabolically', 49, 61), ('active', 63, 68), ('when', 70, 73), ('it', 75, 76), ('combines', 78, 85), ('with', 87, 90), ('membranes', 92, 100), ('and', 102, 104), ('that', 106, 109), ('polyamines', 111, 120), ('might', 122, 126), ('help', 128, 131), ('to', 133, 134), ('regulate', 136, 143), ('this', 145, 148), ('interaction.', 150, 161)]\n",
      "\n",
      "\n",
      "\n",
      "[('This', 0, 3), ('could', 5, 9), ('facilitate', 11, 20), ('the', 22, 24), ('action', 26, 31), ('of', 33, 34), ('fatty', 36, 40), ('acids', 42, 46), ('and', 48, 50), ('enable', 52, 57), ('cells', 59, 63), ('to', 65, 66), ('increase', 68, 75), ('their', 77, 81), ('capacity', 83, 90), ('for', 92, 94), ('triacylglycerol', 96, 110), ('synthesis', 112, 120), ('to', 122, 123), ('match', 125, 129), ('an', 131, 132), ('increased', 134, 142), ('availability', 144, 155), ('of', 157, 158), ('fatty', 160, 164), ('acids.', 166, 171)]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse(\"./data/Devel/2981704.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "for child in root:\n",
    "    (id, text) = (child.attrib[\"id\"], child.attrib[\"text\"])\n",
    "    span_generator = WhitespaceTokenizer().span_tokenize(text)\n",
    "    tokenized_list = tokenize(text, span_generator)\n",
    "    \n",
    "    print(tokenized_list)\n",
    "    print(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
